# -*- coding: utf-8 -*-
"""Proyek_Pertama_Membuat_Model_NLP_dengan_TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14mklqTlVqTxxco0IFR_4m1t2hUQgmFOb

**Proyek Pertama : Membuat Model NLP dengan TensorFlow**

Silahkan rubah Runtime dulu ke mode GPU dengan cara pilih Runtime -> Change Runtime Type -> Pilih GPU -> Save
"""

# Import library 
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import tensorflow as tf
import matplotlib.pyplot as plt

"""**import file Dataset yang akan digunakan**


**Tampilkan 5 data teratas.**
"""

datasetnya = pd.read_csv('bbc-news-data.csv', sep='\t')
datasetnya.head()

"""**Munculkan 5 data teratas**"""

new_dataset = datasetnya.drop(columns=['filename'])
new_dataset.head()

kategori = pd.get_dummies(new_dataset.category)
newest_dataset = pd.concat([new_dataset, kategori], axis=1)
newest_dataset = newest_dataset.drop(columns='category')
newest_dataset

"""**Ubah nilai pada dataframe menjadi sebuah numpy array**"""

bbc_news = newest_dataset['title'].values + '' + newest_dataset['content'].values
bbc_berita = newest_dataset[['business', 'entertainment', 'politics', 'sport', 'tech']].values

# Munculkan isi Array
bbc_news

"""**Lihat label Array**"""

bbc_berita

"""**Bagi data menjadi dua data training dan data Validation**"""

bbc_news_train, bbc_news_test, bbc_berita_train, bbc_berita_test = train_test_split(bbc_news, bbc_berita, test_size=0.2)

"""**Proses Tokenizer**"""

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(bbc_news_train) 
tokenizer.fit_on_texts(bbc_news_test)
 
sekuens_train = tokenizer.texts_to_sequences(bbc_news_train)
sekuens_test = tokenizer.texts_to_sequences(bbc_news_test)
 
padded_train = pad_sequences(sekuens_train) 
padded_test = pad_sequences(sekuens_test)

"""**Implementasikan Embedding pada Keras**"""

model = tf.keras.Sequential([
     tf.keras.layers.Embedding(input_dim=5000, output_dim=64),
     tf.keras.layers.BatchNormalization(),
     tf.keras.layers.LSTM(128),
     tf.keras.layers.Dense(128, activation='relu'),
     tf.keras.layers.Dropout(0.5),
     tf.keras.layers.Dense(5, activation='softmax')
     ])
model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])
model.summary()

"""Implementasi Callback

Untuk menghentikan proses ketika aAkurasi telah melebihi batas yang di tentukan
"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('acc')>0.75 and logs.get('val_acc')>0.9):
      self.model.stop_training = True
      print("\nAkurasinya > 75%!")

es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)
callbacks = myCallback()

"""Proses Fit Model"""

history = model.fit(padded_train, bbc_berita_train, epochs=50, 
                    validation_data=(padded_test, bbc_berita_test), verbose=2, callbacks=[callbacks], validation_steps=30)

"""**Tampilan Model Akurasi**"""

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""**Tampilanlan Model Loss**"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')
plt.show()